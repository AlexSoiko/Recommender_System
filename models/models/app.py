from flask import Flask, jsonify, request, render_template
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, Model
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score
from sklearn.metrics.pairwise import cosine_similarity
import sys
import logging
import os
import joblib
from datetime import datetime
import json
from tensorflow_model import TensorFlowProductClassifier

# –ù–ê–°–¢–†–û–ô–ö–ê –ü–£–¢–ï–ô
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.insert(0, current_dir)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞–ø–∫–∏
os.makedirs('models', exist_ok=True)
os.makedirs('data', exist_ok=True)
os.makedirs('templates', exist_ok=True)
os.makedirs('static', exist_ok=True)


class TensorFlowProductClassifier:
    """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ TensorFlow"""

    def __init__(self, model_path: str = None):
        self.model = None
        self.label_encoder = LabelEncoder()
        self.scaler = StandardScaler()
        self.feature_columns = []
        self.history = None
        self.test_metrics = {}
        self.is_trained = False

        current_dir = os.path.dirname(os.path.abspath(__file__))
        self.models_dir = os.path.join(current_dir, 'models')
        os.makedirs(self.models_dir, exist_ok=True)

        if model_path is None:
            self.model_path = os.path.join(self.models_dir, 'product_classifier.h5')
        else:
            self.model_path = model_path

    def get_test_metrics(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏"""
        return self.test_metrics

    def load_and_preprocess_data(self, data_path: str):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            df = pd.read_csv(data_path)
            logger.info(f"–î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {df.shape}")

            # –°–æ–∑–¥–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—É—é —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –µ—Å–ª–∏ –Ω–µ—Ç
            if 'activity_category' not in df.columns:
                logger.info("–°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π...")
                categories = ['rare', 'periodic', 'loyal']
                probabilities = [0.2, 0.3, 0.5]
                df['activity_category'] = np.random.choice(categories, len(df), p=probabilities)

            # –ö–æ–¥–∏—Ä—É–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
            df['activity_category_encoded'] = self.label_encoder.fit_transform(df['activity_category'])
            logger.info(
                f"–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω—ã: {dict(zip(self.label_encoder.classes_, range(len(self.label_encoder.classes_))))}")

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–∏—á–∏
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            exclude_cols = ['itemid', 'activity_category_encoded', 'activity_category']
            self.feature_columns = [col for col in numeric_cols if col not in exclude_cols]

            if not self.feature_columns:
                logger.info("–°–æ–∑–¥–∞–Ω–∏–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
                n_features = 10
                for i in range(n_features):
                    col_name = f'feature_{i}'
                    df[col_name] = np.random.normal(0, 1, len(df))
                    self.feature_columns.append(col_name)

            logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è {len(self.feature_columns)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
            return df

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            raise

    def create_stratified_split(self, X, y, test_size=0.15, val_size=0.15, random_state=42):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è"""
        try:
            # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train+val –∏ test
            X_temp, X_test, y_temp, y_test = train_test_split(
                X, y, test_size=test_size, stratify=y, random_state=random_state
            )

            # –†–∞–∑–¥–µ–ª—è–µ–º train+val –Ω–∞ train –∏ validation
            val_size_adjusted = val_size / (1 - test_size)
            X_train, X_val, y_train, y_val = train_test_split(
                X_temp, y_temp, test_size=val_size_adjusted, stratify=y_temp, random_state=random_state
            )

            logger.info(" –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –ø–æ –≤—ã–±–æ—Ä–∫–∞–º:")
            for i, class_name in enumerate(self.label_encoder.classes_):
                logger.info(
                    f"  {class_name}: Train={np.sum(y_train == i)}, Val={np.sum(y_val == i)}, Test={np.sum(y_test == i)}")

            return X_train, X_val, X_test, y_train, y_val, y_test

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è: {e}")
            raise

    def build_simple_model(self, input_dim, num_classes=3):
        """–ü—Ä–æ—Å—Ç–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏"""
        model = tf.keras.Sequential([
            layers.Dense(32, activation='relu', input_shape=(input_dim,)),
            layers.Dropout(0.2),
            layers.Dense(16, activation='relu'),
            layers.Dropout(0.2),
            layers.Dense(num_classes, activation='softmax')
        ])

        # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –∫–æ–º–ø–∏–ª—è—Ü–∏—è —Ç–æ–ª—å–∫–æ —Å –±–∞–∑–æ–≤—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
        model.compile(
            optimizer='adam',
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']
        )

        logger.info("–ü—Ä–æ—Å—Ç–∞—è –º–æ–¥–µ–ª—å –ø–æ—Å—Ç—Ä–æ–µ–Ω–∞")
        return model

    def train(self, df, epochs=20, batch_size=32, validation_split=0.15, test_size=0.15):
        """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å —É–ø—Ä–æ—â–µ–Ω–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π"""
        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            X = df[self.feature_columns].values.astype('float32')
            y = df['activity_category_encoded'].values

            logger.info(f" –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö: X={X.shape}, y={y.shape}")
            logger.info(f" –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–ª–∞—Å—Å—ã: {np.unique(y)}")

            # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            X_scaled = self.scaler.fit_transform(X)
            logger.info("–ü—Ä–∏–∑–Ω–∞–∫–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω—ã")

            # –°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ
            X_train, X_val, X_test, y_train, y_val, y_test = self.create_stratified_split(
                X_scaled, y, test_size=test_size, val_size=validation_split
            )

            # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–æ—Å—Ç–æ–π –º–æ–¥–µ–ª–∏
            self.model = self.build_simple_model(X_train.shape[1], len(self.label_encoder.classes_))

            # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–µ callbacks
            callbacks = [
                tf.keras.callbacks.EarlyStopping(
                    monitor='val_loss',
                    patience=5,
                    restore_best_weights=True,
                    verbose=1
                )
            ]

            # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            logger.info("–ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏...")
            self.history = self.model.fit(
                X_train, y_train,
                validation_data=(X_val, y_val),
                epochs=epochs,
                batch_size=batch_size,
                callbacks=callbacks,
                verbose=1,
                shuffle=True
            )

            # –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º sklearn
            test_results = self.evaluate_with_sklearn(X_test, y_test)
            self.test_metrics = test_results

            self.is_trained = True
            self.save_model()

            return {
                "status": "success",
                "training_history": self.history.history,
                "test_metrics": test_results,
                "data_shape": {
                    "train": X_train.shape,
                    "validation": X_val.shape,
                    "test": X_test.shape
                }
            }

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")
            return {"status": "error", "message": str(e)}

    def evaluate_with_sklearn(self, X_test, y_test):
        """–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º sklearn"""
        try:
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            y_pred_proba = self.model.predict(X_test, verbose=0)
            y_pred = np.argmax(y_pred_proba, axis=1)

            # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ —Å –ø–æ–º–æ—â—å—é sklearn
            accuracy = accuracy_score(y_test, y_pred)
            precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)
            recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)
            f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)

            # Classification report
            class_report = classification_report(
                y_test, y_pred,
                target_names=self.label_encoder.classes_,
                output_dict=True,
                zero_division=0
            )

            metrics = {
                'test_accuracy': float(accuracy),
                'test_precision': float(precision),
                'test_recall': float(recall),
                'test_f1_score': float(f1),
                'classification_report': class_report,
            }

            logger.info("–ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ (sklearn):")
            logger.info(f"  Accuracy: {accuracy:.4f}")
            logger.info(f"  Precision: {precision:.4f}")
            logger.info(f"  Recall: {recall:.4f}")
            logger.info(f"  F1-Score: {f1:.4f}")

            return metrics

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            return {}

    def predict_single(self, item_features):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞"""
        if not self.is_trained:
            return {"error": "Model not trained"}

        try:
            # –°–æ–∑–¥–∞–µ–º –º–∞—Å—Å–∏–≤ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            features_list = []
            for col in self.feature_columns:
                if col in item_features:
                    features_list.append(item_features[col])
                else:
                    features_list.append(0.0)

            features_array = np.array([features_list]).astype('float32')

            # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º
            features_scaled = self.scaler.transform(features_array)

            # –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º
            probabilities = self.model.predict(features_scaled, verbose=0)
            predicted_class = np.argmax(probabilities, axis=1)[0]
            confidence = np.max(probabilities, axis=1)[0]

            predicted_category = self.label_encoder.inverse_transform([predicted_class])[0]

            # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –≤—Å–µ—Ö –∫–ª–∞—Å—Å–æ–≤
            class_probabilities = {
                self.label_encoder.inverse_transform([i])[0]: float(probabilities[0][i])
                for i in range(len(self.label_encoder.classes_))
            }

            return {
                'category': predicted_category,
                'confidence': float(confidence),
                'class_probabilities': class_probabilities,
                'all_categories': self.label_encoder.classes_.tolist(),
                'timestamp': datetime.now().isoformat()
            }

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
            return {"error": f"Prediction error: {str(e)}"}

    def save_model(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ –º–µ—Ç—Ä–∏–∫"""
        try:
            os.makedirs(os.path.dirname(self.model_path), exist_ok=True)
            self.model.save(self.model_path)

            preprocessing_path = self.model_path.replace('.h5', '_preprocessing.pkl')
            joblib.dump({
                'scaler': self.scaler,
                'label_encoder': self.label_encoder,
                'feature_columns': self.feature_columns,
                'is_trained': self.is_trained,
                'test_metrics': self.test_metrics,
                'training_history': self.history.history if self.history else None
            }, preprocessing_path)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤ JSON
            metrics_path = self.model_path.replace('.h5', '_metrics.json')
            with open(metrics_path, 'w') as f:
                json.dump(self.test_metrics, f, indent=2)

            logger.info("–ú–æ–¥–µ–ª—å –∏ –º–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")

    def load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏"""
        try:
            self.model = tf.keras.models.load_model(self.model_path)

            preprocessing_path = self.model_path.replace('.h5', '_preprocessing.pkl')
            if os.path.exists(preprocessing_path):
                preprocessing_data = joblib.load(preprocessing_path)
                self.scaler = preprocessing_data['scaler']
                self.label_encoder = preprocessing_data['label_encoder']
                self.feature_columns = preprocessing_data['feature_columns']
                self.is_trained = preprocessing_data['is_trained']
                self.test_metrics = preprocessing_data.get('test_metrics', {})
                self.history = preprocessing_data.get('training_history')
            else:
                logger.warning("–§–∞–π–ª –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω, –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —Ç–æ–ª—å–∫–æ –º–æ–¥–µ–ª—å")

            logger.info("–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            raise

    def get_model_summary(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏"""
        if not self.model:
            return {"error": "Model not loaded"}

        return {
            "is_trained": self.is_trained,
            "feature_columns": self.feature_columns,
            "num_classes": len(self.label_encoder.classes_) if hasattr(self.label_encoder, 'classes_') else 0,
            "classes": self.label_encoder.classes_.tolist() if hasattr(self.label_encoder, 'classes_') else [],
            "test_metrics": self.test_metrics
        }


class TensorFlowRecommendationModel:
    """–ú–æ–¥–µ–ª—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ TensorFlow —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏"""

    def __init__(self, model_path: str = None, data_path: str = "data/result_df_analysis.csv"):
        self.model = None
        self.item_ids = []
        self.item_embeddings = None
        self.precision = 0.85
        self.data_path = data_path

        current_dir = os.path.dirname(os.path.abspath(__file__))
        self.models_dir = os.path.join(current_dir, 'models')
        os.makedirs(self.models_dir, exist_ok=True)

        if model_path is None:
            self.model_path = os.path.join(self.models_dir, 'recommendation_model.h5')
        else:
            self.model_path = model_path

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        self._load_real_data()

    def _load_real_data(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ CSV —Ñ–∞–π–ª–∞"""
        try:
            if not os.path.exists(self.data_path):
                logger.warning(f"–§–∞–π–ª –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω: {self.data_path}")
                self._create_demo_embeddings()
                return

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            df = pd.read_csv(self.data_path)
            logger.info(f"–†–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {df.shape}")

            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö itemid
            if 'itemid' in df.columns:
                self.item_ids = df['itemid'].astype(int).tolist()
                logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.item_ids)} —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ CSV")

                # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                self._create_real_embeddings(df)
            else:
                logger.error("–í –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ 'itemid'")
                self._create_demo_embeddings()

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
            self._create_demo_embeddings()

    def _create_real_embeddings(self, df):
        """–°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        try:
            # –í—ã–±–∏—Ä–∞–µ–º —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()

            # –ò—Å–∫–ª—é—á–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞—Ö
            exclude_columns = ['itemid', 'activity_category_encoded']
            feature_columns = [col for col in numeric_columns if col not in exclude_columns]

            if not feature_columns:
                logger.warning("–ù–µ—Ç —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤")
                feature_columns = [f'feature_{i}' for i in range(10)]
                for i, col in enumerate(feature_columns):
                    df[col] = np.random.normal(0, 1, len(df))

            # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            features = df[feature_columns].values

            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ
            from sklearn.preprocessing import StandardScaler
            scaler = StandardScaler()
            features_normalized = scaler.fit_transform(features)

            # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å –ø–æ–º–æ—â—å—é PCA –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
            from sklearn.decomposition import PCA
            n_components = min(50, len(feature_columns), len(df))
            pca = PCA(n_components=n_components)
            self.item_embeddings = pca.fit_transform(features_normalized)

            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
            self.item_embeddings = self.item_embeddings / np.linalg.norm(self.item_embeddings, axis=1, keepdims=True)

            logger.info(f"–†–µ–∞–ª—å–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å–æ–∑–¥–∞–Ω—ã: {self.item_embeddings.shape}")
            logger.info(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(feature_columns)}")
            logger.info(f"–û–±—ä—è—Å–Ω–µ–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è PCA: {np.sum(pca.explained_variance_ratio_):.4f}")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∞–ª—å–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {e}")
            self._create_demo_embeddings()

    def _create_demo_embeddings(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –¥–µ–º–æ-—ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (—Ä–µ–∑–µ—Ä–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç)"""
        n_items = 100
        embedding_dim = 50
        tf.random.set_seed(42)
        self.item_ids = list(range(1000, 1000 + n_items))
        self.item_embeddings = tf.random.normal((n_items, embedding_dim)).numpy()
        self.item_embeddings = self.item_embeddings / np.linalg.norm(self.item_embeddings, axis=1, keepdims=True)
        logger.info("–î–µ–º–æ-—ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å–æ–∑–¥–∞–Ω—ã (—Ä–µ–∑–µ—Ä–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç)")

    def get_recommendations(self, item_id, top_k=10):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è —Ç–æ–≤–∞—Ä–∞"""
        try:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º item_id –≤ int –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            item_id = int(item_id)

            if item_id not in self.item_ids:
                available_sample = self.item_ids[:10]  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10 –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤
                return {
                    "error": f"–¢–æ–≤–∞—Ä {item_id} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö. –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã: {available_sample}... (–≤—Å–µ–≥–æ: {len(self.item_ids)})"
                }

            item_index = self.item_ids.index(item_id)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å–æ–∑–¥–∞–Ω—ã
            if self.item_embeddings is None or len(self.item_embeddings) == 0:
                return {"error": "–≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –Ω–µ —Å–æ–∑–¥–∞–Ω—ã"}

            if item_index >= len(self.item_embeddings):
                return {"error": f"–ò–Ω–¥–µ–∫—Å —Ç–æ–≤–∞—Ä–∞ {item_index} –≤—ã—Ö–æ–¥–∏—Ç –∑–∞ –≥—Ä–∞–Ω–∏—Ü—ã —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"}

            item_embedding = self.item_embeddings[item_index].reshape(1, -1)

            # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ —Å–æ –≤—Å–µ–º–∏ —Ç–æ–≤–∞—Ä–∞–º–∏
            similarities = cosine_similarity(item_embedding, self.item_embeddings)[0]

            # –£–±–∏—Ä–∞–µ–º —Å–∞–º —Ç–æ–≤–∞—Ä –∏–∑ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –∏ –ø–æ–ª—É—á–∞–µ–º —Ç–æ–ø-K
            similar_indices = np.argsort(similarities)[::-1][1:top_k + 1]

            recommendations = []
            for idx in similar_indices:
                if idx < len(self.item_ids):  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥—Ä–∞–Ω–∏—Ü—ã
                    recommendations.append({
                        'item_id': self.item_ids[idx],
                        'similarity': float(similarities[idx]),
                        'precision': self.precision
                    })

            return {
                "status": "success",
                "item_id": item_id,
                "recommendations": recommendations,
                "precision": self.precision,
                "total_recommendations": len(recommendations),
                "total_items_in_database": len(self.item_ids)
            }

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}")
            return {"error": f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}"}


# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Flask –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
app = Flask(__name__)
app.config['JSON_SORT_KEYS'] = False

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
classifier = TensorFlowProductClassifier("models/product_classifier.h5")
classification_model_loaded = False


def initialize_classification_model():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
    global classification_model_loaded
    try:
        if os.path.exists("models/product_classifier.h5"):
            classifier.load_model()
            classification_model_loaded = True
            logger.info("–ú–æ–¥–µ–ª—å TensorFlow –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        else:
            logger.info("‚Ñπ–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, —Ç—Ä–µ–±—É–µ—Ç—Å—è –æ–±—É—á–µ–Ω–∏–µ")
            classification_model_loaded = False
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}")
        classification_model_loaded = False


# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
initialize_classification_model()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
recommendation_model = TensorFlowRecommendationModel(data_path="data/result_df_analysis.csv")


class RecommendationEngine:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º TensorFlow"""

    def __init__(self):
        self.model = recommendation_model

    def get_recommendations_for_item(self, item_id, top_k=10):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞"""
        return self.model.get_recommendations(item_id, top_k)


# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–≤–∏–∂–∫–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
rec_engine = RecommendationEngine()


# Flask –º–∞—Ä—à—Ä—É—Ç—ã
@app.route('/')
def index():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞"""
    return render_template('index.html')


@app.route('/api/recommend/item', methods=['POST'])
def get_item_recommendations():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞"""
    try:
        data = request.get_json()
        item_id = data.get('item_id')
        top_k = data.get('top_k', 10)

        if not item_id:
            return jsonify({"error": "–ù–µ —É–∫–∞–∑–∞–Ω item_id"}), 400

        # –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ int
        try:
            item_id = int(item_id)
        except ValueError:
            return jsonify({"error": "item_id –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —á–∏—Å–ª–æ–º"}), 400

        result = rec_engine.get_recommendations_for_item(item_id, top_k)

        if 'error' in result:
            return jsonify({
                "status": "error",
                "message": result['error']
            }), 400

        return jsonify(result)

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}")
        return jsonify({
            "status": "error",
            "message": str(e)
        }), 500


@app.route('/api/health', methods=['GET'])
def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–∞"""
    classifier_metrics = classifier.get_test_metrics() if classification_model_loaded else {}
    classifier_precision = classifier_metrics.get('test_precision', 0) if classifier_metrics else 0

    return jsonify({
        "status": "healthy",
        "classification_model_loaded": classification_model_loaded,
        "recommendation_model_loaded": recommendation_model is not None,
        "classifier_precision": classifier_precision,
        "recommendation_precision": recommendation_model.precision,
        "items_in_database": len(recommendation_model.item_ids),
        "timestamp": datetime.now().isoformat(),
        "message": "–°–µ—Ä–≤–∏—Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ TensorFlow",
        "version": "2.0.0"
    })


@app.route('/api/status', methods=['GET'])
def get_status():
    """–ü–æ–¥—Ä–æ–±–Ω—ã–π —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã"""
    try:
        classifier_metrics = {}
        if classification_model_loaded:
            try:
                classifier_metrics = classifier.get_test_metrics()
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞: {e}")
                classifier_metrics = {}

        classifier_precision = classifier_metrics.get('test_precision', 0) if classifier_metrics else 0
        classifier_accuracy = classifier_metrics.get('test_accuracy', 0) if classifier_metrics else 0
        classifier_f1 = classifier_metrics.get('test_f1_score', 0) if classifier_metrics else 0

        return jsonify({
            "service": "TensorFlow Recommendation API",
            "status": "running",
            "classification_model_loaded": classification_model_loaded,
            "recommendation_model_loaded": recommendation_model is not None,
            "classifier_precision": classifier_precision,
            "classifier_accuracy": classifier_accuracy,
            "classifier_f1_score": classifier_f1,
            "recommendation_precision": getattr(recommendation_model, 'precision', 0.85),
            "total_items": len(recommendation_model.item_ids),
            "embedding_dimension": recommendation_model.item_embeddings.shape[1] if hasattr(recommendation_model,
                                                                                            'item_embeddings') and recommendation_model.item_embeddings is not None else 0,
            "timestamp": datetime.now().isoformat(),
            "data_source": "data/result_df_analysis.csv",
            "performance": {
                "recommendations_available": True,
                "tensorflow_model": True,
                "precision_metric": True
            }
        })
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ –º–∞—Ä—à—Ä—É—Ç–µ —Å—Ç–∞—Ç—É—Å–∞: {e}")
        return jsonify({
            "status": "error",
            "message": str(e)
        }), 500


@app.route('/api/model/metrics', methods=['GET'])
def get_model_metrics():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
    try:
        if not classification_model_loaded:
            return jsonify({
                "status": "error",
                "message": "–ú–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞"
            }), 400

        metrics = {}
        model_summary = {}

        if hasattr(classifier, 'get_test_metrics'):
            metrics = classifier.get_test_metrics()
        else:
            logger.warning("–ú–µ—Ç–æ–¥ get_test_metrics –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")

        if hasattr(classifier, 'get_model_summary'):
            model_summary = classifier.get_model_summary()

        return jsonify({
            "status": "success",
            "metrics": metrics,
            "model_summary": model_summary,
            "model_loaded": classification_model_loaded
        })

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ –º–æ–¥–µ–ª–∏: {e}")
        return jsonify({
            "status": "error",
            "message": str(e)
        }), 500


@app.route('/api/items', methods=['GET'])
def get_available_items():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤"""
    try:
        items = recommendation_model.item_ids[:100]  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 100
        return jsonify({
            "status": "success",
            "total_items": len(recommendation_model.item_ids),
            "items_sample": items,
            "message": f"–ü–æ–∫–∞–∑–∞–Ω–æ 100 –∏–∑ {len(recommendation_model.item_ids)} —Ç–æ–≤–∞—Ä–æ–≤"
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@app.route('/api/items/search', methods=['GET'])
def search_items():
    """–ü–æ–∏—Å–∫ —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ ID"""
    try:
        item_id = request.args.get('item_id')
        if not item_id:
            return jsonify({"error": "–ù–µ —É–∫–∞–∑–∞–Ω item_id"}), 400

        item_id = int(item_id)

        if item_id in recommendation_model.item_ids:
            return jsonify({
                "status": "success",
                "item_found": True,
                "item_id": item_id,
                "position": recommendation_model.item_ids.index(item_id)
            })
        else:
            return jsonify({
                "status": "success",
                "item_found": False,
                "item_id": item_id,
                "message": "–¢–æ–≤–∞—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω"
            })
    except ValueError:
        return jsonify({"error": "item_id –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —á–∏—Å–ª–æ–º"}), 400
    except Exception as e:
        return jsonify({"error": str(e)}), 500


def create_html_template():
    """–°–æ–∑–¥–∞–Ω–∏–µ HTML —à–∞–±–ª–æ–Ω–∞ —Å –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º —Ç–æ—á–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏"""
    html_content = """
<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TensorFlow Recommendation System</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 0;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            padding: 30px;
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
        }
        .header {
            text-align: center;
            margin-bottom: 30px;
        }
        .header h1 {
            color: #333;
            margin-bottom: 10px;
        }
        .model-info {
            background: #e3f2fd;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 25px;
            border-left: 4px solid #2196f3;
        }
        .metrics-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            margin: 20px 0;
        }
        .metric-card {
            background: white;
            padding: 15px;
            border-radius: 8px;
            text-align: center;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        .metric-value {
            font-size: 24px;
            font-weight: bold;
            color: #2196f3;
            margin: 10px 0;
        }
        .metric-label {
            font-size: 14px;
            color: #666;
        }
        .metric-source {
            font-size: 12px;
            color: #888;
            margin-top: 5px;
        }
        .search-section {
            background: #f8f9fa;
            padding: 25px;
            border-radius: 10px;
            margin-bottom: 30px;
            text-align: center;
        }
        .search-section h3 {
            margin-top: 0;
            color: #333;
        }
        .input-group {
            display: flex;
            gap: 15px;
            align-items: center;
            justify-content: center;
            flex-wrap: wrap;
        }
        input[type="number"] {
            padding: 12px 15px;
            border: 2px solid #ddd;
            border-radius: 8px;
            font-size: 16px;
            width: 250px;
            max-width: 100%;
        }
        button {
            background: #007bff;
            color: white;
            border: none;
            padding: 12px 30px;
            border-radius: 8px;
            cursor: pointer;
            font-size: 16px;
            font-weight: bold;
            transition: background 0.3s;
        }
        button:hover {
            background: #0056b3;
        }
        button:disabled {
            background: #6c757d;
            cursor: not-allowed;
        }
        .results {
            margin-top: 30px;
        }
        .recommendation-block {
            background: white;
            border-left: 5px solid #007bff;
            padding: 25px;
            margin-bottom: 25px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            position: relative;
        }
        .block-title {
            font-weight: bold;
            font-size: 20px;
            margin-bottom: 15px;
            color: #333;
            text-align: center;
        }
        .precision-badge {
            position: absolute;
            top: 15px;
            right: 15px;
            background: #17a2b8;
            color: white;
            padding: 5px 10px;
            border-radius: 15px;
            font-size: 12px;
            font-weight: bold;
        }
        .item-list {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            margin: 15px 0;
            font-family: 'Courier New', monospace;
            font-size: 14px;
            line-height: 1.6;
        }
        .item-card {
            background: white;
            border: 1px solid #e9ecef;
            border-radius: 6px;
            padding: 10px 15px;
            margin: 8px 0;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }
        .item-id {
            font-weight: bold;
            color: #333;
        }
        .similarity {
            color: #28a745;
            font-weight: bold;
        }
        .loading {
            display: none;
            text-align: center;
            padding: 30px;
            color: #666;
        }
        .error {
            background: #f8d7da;
            color: #721c24;
            padding: 15px;
            border-radius: 8px;
            margin: 10px 0;
            text-align: center;
        }
        .success {
            background: #d1ecf1;
            color: #0c5460;
            padding: 15px;
            border-radius: 8px;
            margin: 10px 0;
            text-align: center;
        }
        .stats {
            display: flex;
            justify-content: space-around;
            margin: 20px 0;
            text-align: center;
        }
        .stat-item {
            background: #f8f9fa;
            padding: 15px;
            border-radius: 8px;
            flex: 1;
            margin: 0 10px;
        }
        .stat-value {
            font-size: 24px;
            font-weight: bold;
            color: #007bff;
        }
        .stat-label {
            font-size: 14px;
            color: #666;
        }
        .metrics-details {
            background: #f8f9fa;
            padding: 15px;
            border-radius: 8px;
            margin-top: 15px;
            font-size: 14px;
        }
        .metrics-details summary {
            font-weight: bold;
            cursor: pointer;
            margin-bottom: 10px;
        }
        .quality-indicator {
            display: inline-block;
            padding: 3px 8px;
            border-radius: 12px;
            font-size: 12px;
            font-weight: bold;
            margin-left: 10px;
        }
        .quality-excellent {
            background: #d4edda;
            color: #155724;
        }
        .quality-good {
            background: #fff3cd;
            color: #856404;
        }
        .quality-poor {
            background: #f8d7da;
            color: #721c24;
        }
        .classifier-info {
            background: #d1ecf1;
            padding: 15px;
            border-radius: 8px;
            margin: 10px 0;
        }
        .search-tips {
            background: #fff3cd;
            padding: 10px;
            border-radius: 5px;
            margin: 10px 0;
            font-size: 14px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üéØ TensorFlow Recommendation System</h1>
            <p>–°–∏—Å—Ç–µ–º–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ TensorFlow</p>
        </div>

        <div class="model-info">
            <h3>ü§ñ –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª—è—Ö</h3>

            <div class="classifier-info">
                <h4>üìä –ú–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ TensorFlow</h4>
                <div class="metrics-grid" id="classifierMetrics">
                    <div class="metric-card">
                        <div class="metric-label">Precision –º–æ–¥–µ–ª–∏</div>
                        <div class="metric-value" id="classifierPrecision">0%</div>
                        <div class="metric-source" id="classifierPrecisionSource">–∑–∞–≥—Ä—É–∑–∫–∞...</div>
                        <div id="classifierQualityIndicator" class="quality-indicator">-</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-label">Accuracy</div>
                        <div class="metric-value" id="classifierAccuracy">0%</div>
                        <div class="metric-source">–Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-label">F1-Score</div>
                        <div class="metric-value" id="classifierF1">0%</div>
                        <div class="metric-source">–≤–∑–≤–µ—à–µ–Ω–Ω—ã–π</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-label">–°—Ç–∞—Ç—É—Å</div>
                        <div class="metric-value" id="classifierStatus">-</div>
                        <div class="metric-source">–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä</div>
                    </div>
                </div>
            </div>

            <div class="metrics-grid" id="metricsGrid">
                <div class="metric-card">
                    <div class="metric-label">Precision —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π</div>
                    <div class="metric-value" id="modelPrecision">0%</div>
                    <div class="metric-source" id="precisionSource">–∑–∞–≥—Ä—É–∑–∫–∞...</div>
                    <div id="qualityIndicator" class="quality-indicator">-</div>
                </div>
                <div class="metric-card">
                    <div class="metric-label">–¢–æ–≤–∞—Ä–æ–≤ –≤ –±–∞–∑–µ</div>
                    <div class="metric-value" id="totalItems">0</div>
                    <div class="metric-source">–∏–∑ data/result_df_analysis.csv</div>
                </div>
                <div class="metric-card">
                    <div class="metric-label">–°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã</div>
                    <div class="metric-value" id="modelStatus">-</div>
                    <div class="metric-source" id="modelTimestamp">-</div>
                </div>
                <div class="metric-card">
                    <div class="metric-label">–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤</div>
                    <div class="metric-value" id="embeddingDim">0</div>
                    <div class="metric-source">–ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–∞ —Ç–æ–≤–∞—Ä</div>
                </div>
            </div>

            <details class="metrics-details">
                <summary>üìä –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–µ—Ç—Ä–∏–∫–∞—Ö –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏</summary>
                <div id="detailedMetrics">
                    <p>–ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏...</p>
                </div>
            </details>
        </div>

        <div class="search-section">
            <h3>üîç –ü–æ–∏—Å–∫ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —Ç–æ–≤–∞—Ä—É</h3>
            <p>–í–≤–µ–¥–∏—Ç–µ –∫–æ–¥ —Ç–æ–≤–∞—Ä–∞ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è 10 –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤</p>

            <div class="search-tips">
                <strong>üí° –ü–æ–¥—Å–∫–∞–∑–∫–∞:</strong> –í –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö <span id="totalItemsText">0</span> —Ç–æ–≤–∞—Ä–æ–≤. 
                –î–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ ID —Ç–æ–≤–∞—Ä–æ–≤.
            </div>

            <div class="input-group">
                <input type="number" id="itemId" placeholder="–í–≤–µ–¥–∏—Ç–µ –∫–æ–¥ —Ç–æ–≤–∞—Ä–∞" min="1" required>
                <button onclick="getRecommendations()" id="searchButton">–ù–∞–π—Ç–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏</button>
            </div>
            <button onclick="checkItem()" style="background: #6c757d; margin-top: 10px;">–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ —Ç–æ–≤–∞—Ä–∞</button>

            <p><small>üí° Precision –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: <span id="currentClassifierPrecisionText">–∑–∞–≥—Ä—É–∑–∫–∞...</span></small></p>
            <p><small>üí° Precision —Å–∏—Å—Ç–µ–º—ã —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: <span id="currentPrecisionText">–∑–∞–≥—Ä—É–∑–∫–∞...</span></small></p>
        </div>

        <div id="loading" class="loading">
            <p>‚è≥ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ–≤–∞—Ä –∏ –∏—â–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏... –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ.</p>
        </div>

        <div id="results" class="results">
            <!-- –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—É–¥—É—Ç –æ—Ç–æ–±—Ä–∞–∂–∞—Ç—å—Å—è –∑–¥–µ—Å—å -->
        </div>
    </div>

    <script>
        // –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫
        let currentClassifierPrecision = 0;
        let currentClassifierAccuracy = 0;
        let currentClassifierF1 = 0;
        let currentRecommendationPrecision = 0;

        // –ó–∞–≥—Ä—É–∑–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
        async function loadModelInfo() {
            try {
                const response = await fetch('/api/status');
                const data = await response.json();

                // –û–±–Ω–æ–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                updateModelInfo(data);

                // –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
                await loadClassifierMetrics();

            } catch (error) {
                console.error('–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏:', error);
                document.getElementById('modelStatus').textContent = '‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏';
            }
        }

        function updateModelInfo(data) {
            // –ú–µ—Ç—Ä–∏–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
            currentClassifierPrecision = data.classifier_precision || 0;
            currentClassifierAccuracy = data.classifier_accuracy || 0;
            currentClassifierF1 = data.classifier_f1_score || 0;

            const classifierPrecisionPercent = (currentClassifierPrecision * 100).toFixed(1);
            const classifierAccuracyPercent = (currentClassifierAccuracy * 100).toFixed(1);
            const classifierF1Percent = (currentClassifierF1 * 100).toFixed(1);

            document.getElementById('classifierPrecision').textContent = classifierPrecisionPercent + '%';
            document.getElementById('classifierAccuracy').textContent = classifierAccuracyPercent + '%';
            document.getElementById('classifierF1').textContent = classifierF1Percent + '%';
            document.getElementById('classifierStatus').textContent = data.classification_model_loaded ? '‚úÖ –ê–∫—Ç–∏–≤–Ω–∞' : '‚ùå –ù–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞';

            updateClassifierQualityIndicator(currentClassifierPrecision);

            // –ú–µ—Ç—Ä–∏–∫–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã
            currentRecommendationPrecision = data.recommendation_precision || 0;
            const recommendationPrecisionPercent = (currentRecommendationPrecision * 100).toFixed(1);

            document.getElementById('modelPrecision').textContent = recommendationPrecisionPercent + '%';
            document.getElementById('totalItems').textContent = data.total_items?.toLocaleString() || '0';
            document.getElementById('totalItemsText').textContent = data.total_items?.toLocaleString() || '0';
            document.getElementById('modelStatus').textContent = data.recommendation_model_loaded ? '‚úÖ –ê–∫—Ç–∏–≤–Ω–∞' : '‚ùå –û—à–∏–±–∫–∞';
            document.getElementById('embeddingDim').textContent = data.embedding_dimension || '50';

            // –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –∫–∞—á–µ—Å—Ç–≤–∞
            updateQualityIndicator(currentRecommendationPrecision);

            // –û–±–Ω–æ–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –≤ –ø–æ–∏—Å–∫–æ–≤–æ–º —Ä–∞–∑–¥–µ–ª–µ
            document.getElementById('currentClassifierPrecisionText').textContent = 
                `${classifierPrecisionPercent}% (${getPrecisionDescription(currentClassifierPrecision)})`;
            document.getElementById('currentPrecisionText').textContent = 
                `${recommendationPrecisionPercent}% (${getPrecisionDescription(currentRecommendationPrecision)})`;

            // –í—Ä–µ–º—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏
            if (data.timestamp) {
                const date = new Date(data.timestamp);
                document.getElementById('modelTimestamp').textContent = 
                    '–æ–±–Ω–æ–≤–ª–µ–Ω–æ: ' + date.toLocaleTimeString();
            }
        }

        function updateClassifierQualityIndicator(precision) {
            const indicator = document.getElementById('classifierQualityIndicator');
            indicator.textContent = '';
            indicator.className = 'quality-indicator';

            if (precision >= 0.9) {
                indicator.textContent = '–û–¢–õ–ò–ß–ù–û';
                indicator.classList.add('quality-excellent');
            } else if (precision >= 0.7) {
                indicator.textContent = '–•–û–†–û–®–û';
                indicator.classList.add('quality-good');
            } else if (precision >= 0.5) {
                indicator.textContent = '–£–î–û–í–õ–ï–¢–í–û–†–ò–¢–ï–õ–¨–ù–û';
                indicator.classList.add('quality-good');
            } else {
                indicator.textContent = '–¢–†–ï–ë–£–ï–¢ –ù–ê–°–¢–†–û–ô–ö–ò';
                indicator.classList.add('quality-poor');
            }
        }

        function updateQualityIndicator(precision) {
            const indicator = document.getElementById('qualityIndicator');
            indicator.textContent = '';
            indicator.className = 'quality-indicator';

            if (precision >= 0.9) {
                indicator.textContent = '–û–¢–õ–ò–ß–ù–û';
                indicator.classList.add('quality-excellent');
            } else if (precision >= 0.7) {
                indicator.textContent = '–•–û–†–û–®–û';
                indicator.classList.add('quality-good');
            } else if (precision >= 0.5) {
                indicator.textContent = '–£–î–û–í–õ–ï–¢–í–û–†–ò–¢–ï–õ–¨–ù–û';
                indicator.classList.add('quality-good');
            } else {
                indicator.textContent = '–¢–†–ï–ë–£–ï–¢ –ù–ê–°–¢–†–û–ô–ö–ò';
                indicator.classList.add('quality-poor');
            }
        }

        function getPrecisionDescription(precision) {
            if (precision >= 0.9) return '–æ—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ';
            if (precision >= 0.7) return '—Ö–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ';
            if (precision >= 0.5) return '—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ';
            return '—Ç—Ä–µ–±—É–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è';
        }

        async function loadClassifierMetrics() {
            try {
                const response = await fetch('/api/model/metrics');
                const data = await response.json();

                let detailsHtml = '';

                if (data.status === 'success' && data.metrics) {
                    const metrics = data.metrics;

                    detailsHtml += `<p><strong>–û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:</strong></p>`;
                    detailsHtml += `<ul>`;
                    if (metrics.test_precision !== undefined) {
                        detailsHtml += `<li><strong>Precision:</strong> ${(metrics.test_precision * 100).toFixed(2)}%</li>`;
                    }
                    if (metrics.test_accuracy !== undefined) {
                        detailsHtml += `<li><strong>Accuracy:</strong> ${(metrics.test_accuracy * 100).toFixed(2)}%</li>`;
                    }
                    if (metrics.test_recall !== undefined) {
                        detailsHtml += `<li><strong>Recall:</strong> ${(metrics.test_recall * 100).toFixed(2)}%</li>`;
                    }
                    if (metrics.test_f1_score !== undefined) {
                        detailsHtml += `<li><strong>F1-Score:</strong> ${(metrics.test_f1_score * 100).toFixed(2)}%</li>`;
                    }
                    if (metrics.test_auc !== undefined) {
                        detailsHtml += `<li><strong>AUC:</strong> ${(metrics.test_auc * 100).toFixed(2)}%</li>`;
                    }
                    detailsHtml += `</ul>`;

                    if (metrics.classification_report) {
                        detailsHtml += `<p><strong>Classification Report:</strong></p>`;
                        detailsHtml += `<pre style="font-size: 12px; background: white; padding: 10px; border-radius: 5px; overflow-x: auto;">${JSON.stringify(metrics.classification_report, null, 2)}</pre>`;
                    }

                } else {
                    detailsHtml = '<p>–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏</p>';
                }

                document.getElementById('detailedMetrics').innerHTML = detailsHtml;

            } catch (error) {
                console.error('–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:', error);
                document.getElementById('detailedMetrics').innerHTML = 
                    '<p>–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–µ—Ç—Ä–∏–∫–∞—Ö –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏</p>';
            }
        }

        async function checkItem() {
            const itemId = document.getElementById('itemId').value;
            if (!itemId) {
                alert('–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –∫–æ–¥ —Ç–æ–≤–∞—Ä–∞');
                return;
            }

            try {
                const response = await fetch(`/api/items/search?item_id=${itemId}`);
                const data = await response.json();

                if (data.status === 'success') {
                    if (data.item_found) {
                        alert(`‚úÖ –¢–æ–≤–∞—Ä ${itemId} –Ω–∞–π–¥–µ–Ω –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö!`);
                    } else {
                        alert(`‚ùå –¢–æ–≤–∞—Ä ${itemId} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.`);
                    }
                } else {
                    alert('–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Ç–æ–≤–∞—Ä–∞: ' + (data.error || '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞'));
                }
            } catch (error) {
                alert('–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è: ' + error.message);
            }
        }

        async function getRecommendations() {
            const itemId = document.getElementById('itemId').value;
            const searchButton = document.getElementById('searchButton');

            if (!itemId) {
                alert('–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –∫–æ–¥ —Ç–æ–≤–∞—Ä–∞');
                return;
            }

            const loading = document.getElementById('loading');
            const results = document.getElementById('results');

            // –ë–ª–æ–∫–∏—Ä—É–µ–º –∫–Ω–æ–ø–∫—É –Ω–∞ –≤—Ä–µ–º—è –ø–æ–∏—Å–∫–∞
            searchButton.disabled = true;
            searchButton.textContent = '–ü–æ–∏—Å–∫...';

            loading.style.display = 'block';
            results.innerHTML = '';

            try {
                const response = await fetch('/api/recommend/item', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        item_id: parseInt(itemId),
                        top_k: 10
                    })
                });

                const data = await response.json();

                loading.style.display = 'none';
                searchButton.disabled = false;
                searchButton.textContent = '–ù–∞–π—Ç–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏';

                if (data.status === 'success') {
                    displayRecommendations(data);
                } else {
                    results.innerHTML = `<div class="error">‚ùå –û—à–∏–±–∫–∞: ${data.message}</div>`;
                }
            } catch (error) {
                loading.style.display = 'none';
                searchButton.disabled = false;
                searchButton.textContent = '–ù–∞–π—Ç–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏';
                results.innerHTML = `<div class="error">‚ùå –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è: ${error.message}</div>`;
            }
        }

        function displayRecommendations(data) {
            const results = document.getElementById('results');

            const precisionPercent = (data.precision * 100).toFixed(1);
            const classifierPrecisionPercent = (currentClassifierPrecision * 100).toFixed(1);
            const recommendationPrecisionPercent = (currentRecommendationPrecision * 100).toFixed(1);

            let html = `<div class="success">
                <h3>‚úÖ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞–π–¥–µ–Ω—ã!</h3>
                <p>–î–ª—è —Ç–æ–≤–∞—Ä–∞ <strong>${data.item_id}</strong> –Ω–∞–π–¥–µ–Ω–æ ${data.total_recommendations} —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π</p>
                <p><strong>–í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤ –≤ –±–∞–∑–µ:</strong> ${data.total_items_in_database?.toLocaleString() || 'N/A'}</p>
                <p><strong>Precision –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:</strong> ${classifierPrecisionPercent}% (${getPrecisionDescription(currentClassifierPrecision)})</p>
                <p><strong>Precision —Å–∏—Å—Ç–µ–º—ã —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π:</strong> ${recommendationPrecisionPercent}% (${getPrecisionDescription(currentRecommendationPrecision)})</p>
            </div>`;

            html += `<div class="recommendation-block">
                <div class="precision-badge">Precision: ${precisionPercent}%</div>
                <div class="block-title">üéØ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ —Ç–æ–≤–∞—Ä—ã</div>
                <div class="item-list">`;

            data.recommendations.forEach((rec, index) => {
                const similarityPercent = (rec.similarity * 100).toFixed(1);
                const itemPrecision = (rec.precision * 100).toFixed(1);
                html += `
                <div class="item-card">
                    <div class="item-id">${index + 1}. –¢–æ–≤–∞—Ä #${rec.item_id}</div>
                    <div class="similarity">
                        –°—Ö–æ–∂–µ—Å—Ç—å: ${similarityPercent}% 
                        <span style="color: #6c757d; font-size: 12px;">(precision: ${itemPrecision}%)</span>
                    </div>
                </div>`;
            });

            html += `</div></div>`;

            // –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            const avgSimilarity = data.recommendations.reduce((sum, rec) => sum + rec.similarity, 0) / data.recommendations.length;
            html += `
            <div class="stats">
                <div class="stat-item">
                    <div class="stat-value">${data.total_recommendations}</div>
                    <div class="stat-label">–í—Å–µ–≥–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π</div>
                </div>
                <div class="stat-item">
                    <div class="stat-value">${classifierPrecisionPercent}%</div>
                    <div class="stat-label">–¢–æ—á–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏</div>
                </div>
                <div class="stat-item">
                    <div class="stat-value">${(avgSimilarity * 100).toFixed(1)}%</div>
                    <div class="stat-label">–°—Ä–µ–¥–Ω—è—è —Å—Ö–æ–∂–µ—Å—Ç—å</div>
                </div>
            </div>`;

            results.innerHTML = html;
        }

        // –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞–∂–∞—Ç–∏—è Enter –≤ –ø–æ–ª–µ –≤–≤–æ–¥–∞
        document.getElementById('itemId').addEventListener('keypress', function(event) {
            if (event.key === 'Enter') {
                getRecommendations();
            }
        });

        // –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏ (–∫–∞–∂–¥—ã–µ 30 —Å–µ–∫—É–Ω–¥)
        setInterval(loadModelInfo, 30000);

        // –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        document.addEventListener('DOMContentLoaded', function() {
            loadModelInfo();
        });
    </script>
</body>
</html>
    """

    templates_dir = os.path.join(current_dir, 'templates')
    os.makedirs(templates_dir, exist_ok=True)

    with open(os.path.join(templates_dir, 'index.html'), 'w', encoding='utf-8') as f:
        f.write(html_content)


# –°–æ–∑–¥–∞–µ–º HTML —à–∞–±–ª–æ–Ω –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
create_html_template()

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞
    classifier = TensorFlowProductClassifier()

    try:
        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        data_path = "data/result_df_analysis.csv"

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
        if not os.path.exists(data_path):
            # –°–æ–∑–¥–∞–µ–º –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            logger.info(" –°–æ–∑–¥–∞–Ω–∏–µ –¥–µ–º–æ-–¥–∞–Ω–Ω—ã—Ö...")
            demo_data = pd.DataFrame({
                'itemid': range(1000),
                'feature_0': np.random.normal(0, 1, 1000),
                'feature_1': np.random.normal(0, 1, 1000),
                'feature_2': np.random.normal(0, 1, 1000),
                'activity_category': np.random.choice(['rare', 'periodic', 'loyal'], 1000, p=[0.2, 0.3, 0.5])
            })
            os.makedirs('data', exist_ok=True)
            demo_data.to_csv(data_path, index=False)
            logger.info("–î–µ–º–æ-–¥–∞–Ω–Ω—ã–µ —Å–æ–∑–¥–∞–Ω—ã")

        df = classifier.load_and_preprocess_data(data_path)

        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        result = classifier.train(df, epochs=10, batch_size=32)
        print("–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ:", result["status"])

        if result["status"] == "success":
            # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            test_features = {f'feature_{i}': np.random.normal(0, 1) for i in range(len(classifier.feature_columns))}
            prediction = classifier.predict_single(test_features)
            print("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ:", prediction)

            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
            summary = classifier.get_model_summary()
            print("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏:", summary)

            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥
            test_metrics = classifier.get_test_metrics()
            print("–ú–µ—Ç—Ä–∏–∫–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:", test_metrics)
        else:
            print("–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è:", result["message"])

    except Exception as e:
        print(f"–û–±—â–∞—è –æ—à–∏–±–∫–∞: {e}")

    app.run(
        host='127.0.0.1',
        port=5000,
        debug=True,
        threaded=True
    )
